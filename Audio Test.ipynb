{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4835294a-2e6d-4b09-9dcc-7f141c96bdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "from librosa import display\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "import torch\n",
    "import lightning as L\n",
    "from IPython.display import Audio\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186d5a6b-72aa-4f2d-9c6d-c73556c92581",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=Path(\"/home/kureta/Music/Chorale Samples/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8fc375-668d-42ec-8408-39b74bbbdd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(fname):\n",
    "    sound = librosa.load(fname, sr=44100, mono=True)[0]\n",
    "    stft = librosa.stft(sound, n_fft=1024, hop_length=512, window='hann')\n",
    "    spec = np.abs(stft)[1:]\n",
    "    \n",
    "    return librosa.amplitude_to_db(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0bee60-28cf-4539-9602-2fc8a3a49166",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(12) as p:\n",
    "    spectra = p.map(prepare, dir.glob(\"*.mp3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c903d64-8e22-45b7-8486-3bbb8d741a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.specshow(spectra[0][:, :1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7718d76d-a001-4258-8c02-fcbed3c03d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.from_numpy(np.concatenate(spectra, axis=1).T)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f320d6d9-caf4-4c3d-9afb-dba37c2f8297",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 8),\n",
    "            torch.nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(8, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 512),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "class AutoEncoder(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ae = AE()\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        pred = self.ae(batch)\n",
    "        loss = torch.nn.functional.mse_loss(pred, batch)\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        dur = 2048\n",
    "        with torch.inference_mode():\n",
    "            pred = self.ae(data[:dur])\n",
    "\n",
    "        result = np.zeros((513, dur))\n",
    "        result[1:, :] = pred.T.cpu().numpy()\n",
    "        # y = librosa.griffinlim(librosa.db_to_amplitude(result), n_iter=100, hop_length=512, n_fft=1024, window='hann')\n",
    "        y = librosa.griffinlim(result, n_iter=100, hop_length=512, n_fft=1024, window='hann')\n",
    "        write_audio(f'test_{self.global_step}.wav', y, 44100)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "        return optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cecf252-837b-4180-8e8f-f1cf63b8098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder.load_from_checkpoint('./lightning_logs/version_0/checkpoints/epoch=249-step=278500.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77182526-44aa-4574-b4e6-82c47c24ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    pred = model.ae(data[:1024].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d707bb5c-ac62-4e75-961b-e8eaa0436d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.zeros((513, 1024))\n",
    "result[1:,] = pred.T.cpu().numpy()\n",
    "result = librosa.db_to_amplitude(result)\n",
    "y = librosa.griffinlim(result, n_iter=1024, hop_length=512, n_fft=1024, window='hann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f94381-c0c7-469b-a140-66cddac31e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.specshow(result)\n",
    "Audio(y, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf6946b-e5fa-490e-9a9a-5d9a64402308",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spec(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64deb43-68e4-4909-a45f-ca195fc285d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Spec(data)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset, batch_size=32, shuffle=True, num_workers=8, prefetch_factor=4, persistent_workers=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97182488-bec4-4a6a-a7b5-bd3da46da8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac4f7b-0b42-44a5-8dda-d3d0799048d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model (hint: here are some helpful Trainer arguments for rapid idea iteration)\n",
    "trainer = L.Trainer(max_steps=10000, limit_val_batches=1, accelerator=\"gpu\", devices=1)\n",
    "trainer.fit(model=model, train_dataloaders=loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87085c4-fb59-4e4f-a7ab-630b4c14ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.06\n",
    "length = 512\n",
    "t = np.arange(start=0, stop=dt*length, step=dt)\n",
    "seed = np.zeros((length, 8))\n",
    "for idx in range(8):\n",
    "    phase = np.random.rand(1) * 2 * np.pi\n",
    "    freq = np.random.rand(1)\n",
    "    amp = np.random.rand() * 50.\n",
    "    seed[:, idx] = amp * np.sin(t * freq + phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6476f12-7393-4704-8253-985d441d4f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    pred = model.ae(data[:1024] * dmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcfceb7-fd10-4afa-a629-621085be5ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.specshow(pred.T.numpy())\n",
    "plt.show()\n",
    "display.specshow(data[:1024].T.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429f6bf4-a5c6-4f4d-997c-e7f84dfe1204",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.zeros((513, length))\n",
    "result[1:,] = pred.T\n",
    "y = librosa.griffinlim(result, n_iter=100, hop_length=512, n_fft=1024, window='hann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f69f7-84b2-47aa-a563-afe9d70ed326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from soundfile import write as write_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7732c02f-2cea-469a-921d-ef1319adabf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_audio('test.wav', y, 44100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
